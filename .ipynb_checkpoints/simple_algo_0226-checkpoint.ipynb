{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a76143db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scheduling Results:\n",
      "Total Energy Consumption (Watt-minutes): 2534400\n",
      "Job Success Rate (%): 100.00\n",
      "Number of Active Hosts: 1\n",
      "Node node-11 - State: Active, CPU Used: 207.7720833333335, Power: 4400 Watts\n",
      "Node node-13 - State: Idle, CPU Used: 0, Power: 3080 Watts\n",
      "Node node-14 - State: Idle, CPU Used: 0, Power: 3080 Watts\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "# Node Specifications (Using node-32 specs for all nodes)\n",
    "NODE_SPEC = {\n",
    "    \"cpu_cores\": 32,  # 16 cores * 2\n",
    "    \"memory_gb\": 256,\n",
    "    \"gpu_count\": 8,  # NVIDIA Tesla V100 (32GB each)\n",
    "    \"gpu_memory_gb\": 32 * 8,  # Total GPU memory\n",
    "    \"power_active\": 4400,  # Watts (2200 * 2)\n",
    "    \"power_idle\": 3080,    # 70% of active\n",
    "    \"power_standby\": 440   # 10% of active\n",
    "}\n",
    "\n",
    "# Constants from the paper\n",
    "JOB_TYPES = [\"AR\", \"IM\", \"BE\"]  # Advance Reservation, Immediate, Best Effort\n",
    "JOB_DISTRIBUTION = {\"AR\": 0.2, \"IM\": 0.3, \"BE\": 0.5}  # Percentage of each job type\n",
    "IDLE_THRESHOLD_MINUTES = 30  # I_th\n",
    "MIN_IDLE_HOSTS = 1\n",
    "\n",
    "# Load workload data (start and end resources are identical in your data)\n",
    "start_resources = pd.DataFrame({\n",
    "    \"hour\": [\"2024-11-04 14:00:00\", \"2024-11-04 15:00:00\", \n",
    "             \"2024-11-04 16:00:00\", \"2024-11-04 17:00:00\"],\n",
    "    \"cpu_load\": [338.745, 347.4925, 386.78, 415.544166666667],\n",
    "    \"cpu_alloc\": [363.0, 363.0, 401.5, 435.666666666667],\n",
    "    \"cpu_idle\": [101.0, 101.0, 62.5, 28.3333333333333],\n",
    "    \"cpu_total\": [464.0, 464.0, 464.0, 464.0],\n",
    "    \"gpu_power_usage\": [701.2725, 727.0759375, 740.7378125, 700.7115625],\n",
    "    \"gpu_mem_used\": [22989.375, 24519.2083333333, 24766.25, 24732.7291666667],\n",
    "    \"gpu_gpu_usage\": [65.5625, 91.75, 92.9895833333333, 61.0104166666667],\n",
    "    \"gpu_fan\": [89.0, 89.0, 89.0, 89.0]\n",
    "})\n",
    "\n",
    "end_resources = start_resources.copy()  # End resources are 1 hour later, identical in your data\n",
    "\n",
    "# Function to classify jobs based on resource usage\n",
    "def classify_jobs(cpu_load: float, job_dist: Dict) -> List[Tuple[str, float]]:\n",
    "    total_load = cpu_load\n",
    "    jobs = []\n",
    "    for job_type, perc in job_dist.items():\n",
    "        load = total_load * perc\n",
    "        jobs.append((job_type, load))\n",
    "        \n",
    "    \n",
    "    return jobs\n",
    "\n",
    "# Node class to manage state and resources\n",
    "class Node:\n",
    "    def __init__(self, name: str):\n",
    "        self.name = name\n",
    "        self.state = \"Idle\"  # Start in Idle state\n",
    "        self.cpu_used = 0\n",
    "        self.gpu_power_used = 0\n",
    "        self.gpu_mem_used = 0\n",
    "        self.vm_queue = []  # List of jobs (VM requests) in queue\n",
    "        self.last_active_time = None\n",
    "        self.available_time = 0  # Earliest available time for VMs\n",
    "\n",
    "    def update_state(self, time_minutes: float, job_load: float = 0):\n",
    "        if job_load > 0 and self.state in [\"Idle\", \"Standby\"]:\n",
    "            self.state = \"Active\"\n",
    "            self.last_active_time = time_minutes\n",
    "        elif job_load == 0 and self.state == \"Active\":\n",
    "            if time_minutes - self.last_active_time > IDLE_THRESHOLD_MINUTES:\n",
    "                self.state = \"Standby\"\n",
    "            else:\n",
    "                self.state = \"Idle\"\n",
    "        self.cpu_used = job_load\n",
    "\n",
    "    def get_power_consumption(self) -> float:\n",
    "        if self.state == \"Active\":\n",
    "            return NODE_SPEC[\"power_active\"]\n",
    "        elif self.state == \"Idle\":\n",
    "            return NODE_SPEC[\"power_idle\"]\n",
    "        else:  # Standby\n",
    "            return NODE_SPEC[\"power_standby\"]\n",
    "\n",
    "# EAVMAT Scheduling Algorithm\n",
    "def eavmat_scheduling(nodes: List[Node], workload: pd.DataFrame) -> Dict:\n",
    "    results = {\"energy_consumption\": 0, \"job_success_rate\": 0, \"active_hosts\": 0}\n",
    "    total_jobs = 0\n",
    "    successful_jobs = 0\n",
    "\n",
    "    for idx, row in workload.iterrows():\n",
    "        time = pd.to_datetime(row[\"hour\"])\n",
    "        cpu_load = row[\"cpu_load\"]\n",
    "        gpu_power = row[\"gpu_power_usage\"]\n",
    "        gpu_mem = row[\"gpu_mem_used\"]\n",
    "\n",
    "        # Classify jobs into AR, IM, BE\n",
    "        jobs = classify_jobs(cpu_load, JOB_DISTRIBUTION)\n",
    "        total_jobs += len(jobs)\n",
    "\n",
    "        # Sort nodes by available time (simplistic approach for demonstration)\n",
    "        available_nodes = sorted(nodes, key=lambda x: x.available_time)\n",
    "        active_nodes = [n for n in nodes if n.state == \"Active\"]\n",
    "        idle_nodes = [n for n in nodes if n.state == \"Idle\"]\n",
    "\n",
    "        for job_type, load in jobs:\n",
    "            scheduled = False\n",
    "            # Try to schedule on active nodes first\n",
    "            for node in active_nodes:\n",
    "                if node.cpu_used + load <= NODE_SPEC[\"cpu_cores\"] * 100:  # Assume 100 units/core\n",
    "                    node.cpu_used += load\n",
    "                    node.update_state((time - pd.Timestamp(\"2024-11-04 14:00:00\")).total_seconds() / 60, load)\n",
    "                    node.available_time = (time + timedelta(hours=1) - pd.Timestamp(\"2024-11-04 14:00:00\")).total_seconds() / 60\n",
    "                    scheduled = True\n",
    "                    successful_jobs += 1\n",
    "                    break\n",
    "\n",
    "            if not scheduled and idle_nodes:\n",
    "                # Use idle node, transition to Active\n",
    "                node = idle_nodes[0]\n",
    "                if node.cpu_used + load <= NODE_SPEC[\"cpu_cores\"] * 100:\n",
    "                    node.cpu_used += load\n",
    "                    node.update_state((time - pd.Timestamp(\"2024-11-04 14:00:00\")).total_seconds() / 60, load)\n",
    "                    node.available_time = (time + timedelta(hours=1) - pd.Timestamp(\"2024-11-04 14:00:00\")).total_seconds() / 60\n",
    "                    node.state = \"Active\"\n",
    "                    scheduled = True\n",
    "                    successful_jobs += 1\n",
    "\n",
    "            if not scheduled and job_type in [\"AR\", \"IM\"]:\n",
    "                # Preempt BE job if possible (simplified: assume BE jobs can be preempted)\n",
    "                for node in active_nodes:\n",
    "                    if node.vm_queue and any(j[0] == \"BE\" for j in node.vm_queue):\n",
    "                        # Preempt BE job (remove it, schedule new job)\n",
    "                        node.vm_queue = [j for j in node.vm_queue if j[0] != \"BE\"]\n",
    "                        node.cpu_used += load\n",
    "                        node.update_state((time - pd.Timestamp(\"2024-11-04 14:00:00\")).total_seconds() / 60, load)\n",
    "                        node.available_time = (time + timedelta(hours=1) - pd.Timestamp(\"2024-11-04 14:00:00\")).total_seconds() / 60\n",
    "                        scheduled = True\n",
    "                        successful_jobs += 1\n",
    "                        break\n",
    "\n",
    "            if not scheduled:\n",
    "                # Job rejected (e.g., for AR/IM if no resources available)\n",
    "                continue\n",
    "\n",
    "    # Calculate energy consumption over 4 hours (240 minutes)\n",
    "    total_time_minutes = 240\n",
    "    for node in nodes:\n",
    "        state_time = total_time_minutes  # Simplified: assume node stays in current state for entire period\n",
    "        results[\"energy_consumption\"] += node.get_power_consumption() * state_time\n",
    "\n",
    "    results[\"job_success_rate\"] = (successful_jobs / total_jobs) * 100 if total_jobs > 0 else 0\n",
    "    results[\"active_hosts\"] = len([n for n in nodes if n.state == \"Active\"])\n",
    "\n",
    "    return results\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize nodes (node-11, node-13, node-14)\n",
    "    nodes = [Node(f\"node-{i}\") for i in [11, 13, 14]]\n",
    "\n",
    "    # Run EAVMAT scheduling\n",
    "    results = eavmat_scheduling(nodes, start_resources)\n",
    "\n",
    "    # Print results\n",
    "    print(\"Scheduling Results:\")\n",
    "    print(f\"Total Energy Consumption (Watt-minutes): {results['energy_consumption']}\")\n",
    "    print(f\"Job Success Rate (%): {results['job_success_rate']:.2f}\")\n",
    "    print(f\"Number of Active Hosts: {results['active_hosts']}\")\n",
    "\n",
    "    # Optional: Print node states\n",
    "    for node in nodes:\n",
    "        print(f\"Node {node.name} - State: {node.state}, CPU Used: {node.cpu_used}, Power: {node.get_power_consumption()} Watts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82523ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048b3894",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f6b602",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a06df35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(workload[\"cpu_load\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e1fd27",
   "metadata": {},
   "source": [
    "## 加上更多資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05813328",
   "metadata": {},
   "outputs": [],
   "source": [
    "NODE_SPEC = {\n",
    "    \"node-32\": {\n",
    "        \"cpu_cores\": 32,  # 16 * 2\n",
    "        \"memory_gb\": 256,\n",
    "        \"gpu_count\": 8,  # NVIDIA Tesla V100 (32G) * 8\n",
    "        \"gpu_memory_gb\": 32 * 8,  # Total GPU memory\n",
    "        \"power_active\": 4400,  # 2200 * 2\n",
    "        \"power_idle\": 3080,    # 70% of active\n",
    "        \"power_standby\": 440   # 10% of active\n",
    "    },\n",
    "    \"node-11\": {\n",
    "        \"cpu_cores\": 44,  # 22 * 2\n",
    "        \"memory_gb\": 512,\n",
    "        \"gpu_count\": 0,   # No GPU\n",
    "        \"gpu_memory_gb\": 0,\n",
    "        \"power_active\": 2200,  # 1100 * 2\n",
    "        \"power_idle\": 1540,    # 70% of active\n",
    "        \"power_standby\": 220   # 10% of active\n",
    "    },\n",
    "    \"node-12\": {\n",
    "        \"cpu_cores\": 44,  # 22 * 2\n",
    "        \"memory_gb\": 512,\n",
    "        \"gpu_count\": 0,   # No GPU\n",
    "        \"gpu_memory_gb\": 0,\n",
    "        \"power_active\": 2200,  # 1100 * 2\n",
    "        \"power_idle\": 1540,    # 70% of active\n",
    "        \"power_standby\": 220   # 10% of active\n",
    "    },\n",
    "    \"node-13\": {\n",
    "        \"cpu_cores\": 44,  # 22 * 2\n",
    "        \"memory_gb\": 512,\n",
    "        \"gpu_count\": 0,   # No GPU\n",
    "        \"gpu_memory_gb\": 0,\n",
    "        \"power_active\": 2200,  # 1100 * 2\n",
    "        \"power_idle\": 1540,    # 70% of active\n",
    "        \"power_standby\": 220   # 10% of active\n",
    "    },\n",
    "    \"node-14\": {\n",
    "        \"cpu_cores\": 96,  # 24 * 4\n",
    "        \"memory_gb\": 512,\n",
    "        \"gpu_count\": 0,   # No GPU\n",
    "        \"gpu_memory_gb\": 0,\n",
    "        \"power_active\": 2200,  # 1100 * 2\n",
    "        \"power_idle\": 1540,    # 70% of active\n",
    "        \"power_standby\": 220   # 10% of active\n",
    "    },\n",
    "    \"esxi-31\": {\n",
    "        \"cpu_cores\": 28,  # 14 * 2\n",
    "        \"memory_gb\": 256,\n",
    "        \"gpu_count\": 2,   # NVIDIA Tesla V100 (16G) * 2\n",
    "        \"gpu_memory_gb\": 16 * 2,  # Total GPU memory\n",
    "        \"power_active\": 3200,  # 1600 * 2\n",
    "        \"power_idle\": 2240,    # 70% of active\n",
    "        \"power_standby\": 320   # 10% of active\n",
    "    },\n",
    "    \"node-15\": {\n",
    "        \"cpu_cores\": 4,\n",
    "        \"memory_gb\": 256,  # Assumed from esxi-31\n",
    "        \"gpu_count\": 1,   # NVIDIA Tesla V100 (16G) * 1\n",
    "        \"gpu_memory_gb\": 16,\n",
    "        \"power_active\": 1600,  # Assumed from esxi-31\n",
    "        \"power_idle\": 1120,    # 70% of active\n",
    "        \"power_standby\": 160   # 10% of active\n",
    "    },\n",
    "    \"node-16\": {\n",
    "        \"cpu_cores\": 4,\n",
    "        \"memory_gb\": 256,  # Assumed from esxi-31\n",
    "        \"gpu_count\": 1,   # NVIDIA Tesla V100 (16G) * 1\n",
    "        \"gpu_memory_gb\": 16,\n",
    "        \"power_active\": 1600,  # Assumed from esxi-31\n",
    "        \"power_idle\": 1120,    # 70% of active\n",
    "        \"power_standby\": 160   # 10% of active\n",
    "    },\n",
    "    \"node-17\": {\n",
    "        \"cpu_cores\": 36,  # 18 * 2\n",
    "        \"memory_gb\": 256,\n",
    "        \"gpu_count\": 0,   # No GPU\n",
    "        \"gpu_memory_gb\": 0,\n",
    "        \"power_active\": 3200,  # 1600 * 2\n",
    "        \"power_idle\": 2240,    # 70% of active\n",
    "        \"power_standby\": 320   # 10% of active\n",
    "    },\n",
    "    \"node-18\": {\n",
    "        \"cpu_cores\": 36,  # 18 * 2\n",
    "        \"memory_gb\": 256,\n",
    "        \"gpu_count\": 0,   # No GPU\n",
    "        \"gpu_memory_gb\": 0,\n",
    "        \"power_active\": 3200,  # 1600 * 2\n",
    "        \"power_idle\": 2240,    # 70% of active\n",
    "        \"power_standby\": 320   # 10% of active\n",
    "    },\n",
    "    \"node-19\": {\n",
    "        \"cpu_cores\": 80,  # 20 * 4\n",
    "        \"memory_gb\": 128,\n",
    "        \"gpu_count\": 0,   # No GPU\n",
    "        \"gpu_memory_gb\": 0,\n",
    "        \"power_active\": 6400,  # 1600 * 4\n",
    "        \"power_idle\": 4480,    # 70% of active\n",
    "        \"power_standby\": 640   # 10% of active\n",
    "    },\n",
    "    \"esxi-33\": {\n",
    "        \"cpu_cores\": 36,  # 18 * 2\n",
    "        \"memory_gb\": 256,\n",
    "        \"gpu_count\": 8,   # NVIDIA GeForce RTX2080Ti * 8\n",
    "        \"gpu_memory_gb\": 11 * 8,  # Approx. 11GB per RTX2080Ti\n",
    "        \"power_active\": 4400,  # 2200 * 2\n",
    "        \"power_idle\": 3080,    # 70% of active\n",
    "        \"power_standby\": 440   # 10% of active\n",
    "    },\n",
    "    \"node-151\": {\n",
    "        \"cpu_cores\": 4,\n",
    "        \"memory_gb\": 256,  # Assumed from esxi-33\n",
    "        \"gpu_count\": 0,   # No GPU\n",
    "        \"gpu_memory_gb\": 0,\n",
    "        \"power_active\": 2200,  # Assumed from esxi-33\n",
    "        \"power_idle\": 1540,    # 70% of active\n",
    "        \"power_standby\": 220   # 10% of active\n",
    "    },\n",
    "    \"node-152\": {\n",
    "        \"cpu_cores\": 4,\n",
    "        \"memory_gb\": 256,  # Assumed from esxi-33\n",
    "        \"gpu_count\": 1,   # NVIDIA GeForce RTX2080Ti * 1\n",
    "        \"gpu_memory_gb\": 11,\n",
    "        \"power_active\": 2200,  # Assumed from esxi-33\n",
    "        \"power_idle\": 1540,    # 70% of active\n",
    "        \"power_standby\": 220   # 10% of active\n",
    "    },\n",
    "    \"node-153\": {\n",
    "        \"cpu_cores\": 4,\n",
    "        \"memory_gb\": 256,  # Assumed from esxi-33\n",
    "        \"gpu_count\": 1,   # NVIDIA GeForce RTX2080Ti * 1\n",
    "        \"gpu_memory_gb\": 11,\n",
    "        \"power_active\": 2200,  # Assumed from esxi-33\n",
    "        \"power_idle\": 1540,    # 70% of active\n",
    "        \"power_standby\": 220   # 10% of active\n",
    "    },\n",
    "    \"node-154\": {\n",
    "        \"cpu_cores\": 4,\n",
    "        \"memory_gb\": 256,  # Assumed from esxi-33\n",
    "        \"gpu_count\": 1,   # NVIDIA GeForce RTX2080Ti * 1\n",
    "        \"gpu_memory_gb\": 11,\n",
    "        \"power_active\": 2200,  # Assumed from esxi-33\n",
    "        \"power_idle\": 1540,    # 70% of active\n",
    "        \"power_standby\": 220   # 10% of active\n",
    "    },\n",
    "    \"node-155\": {\n",
    "        \"cpu_cores\": 4,\n",
    "        \"memory_gb\": 256,  # Assumed from esxi-33\n",
    "        \"gpu_count\": 1,   # NVIDIA GeForce RTX2080Ti * 1\n",
    "        \"gpu_memory_gb\": 11,\n",
    "        \"power_active\": 2200,  # Assumed from esxi-33\n",
    "        \"power_idle\": 1540,    # 70% of active\n",
    "        \"power_standby\": 220   # 10% of active\n",
    "    },\n",
    "    \"node-156\": {\n",
    "        \"cpu_cores\": 4,\n",
    "        \"memory_gb\": 256,  # Assumed from esxi-33\n",
    "        \"gpu_count\": 0,   # No GPU\n",
    "        \"gpu_memory_gb\": 0,\n",
    "        \"power_active\": 2200,  # Assumed from esxi-33\n",
    "        \"power_idle\": 1540,    # 70% of active\n",
    "        \"power_standby\": 220   # 10% of active\n",
    "    },\n",
    "    \"node-157\": {\n",
    "        \"cpu_cores\": 4,\n",
    "        \"memory_gb\": 256,  # Assumed from esxi-33\n",
    "        \"gpu_count\": 0,   # No GPU\n",
    "        \"gpu_memory_gb\": 0,\n",
    "        \"power_active\": 2200,  # Assumed from esxi-33\n",
    "        \"power_idle\": 1540,    # 70% of active\n",
    "        \"power_standby\": 220   # 10% of active\n",
    "    },\n",
    "    \"node-158\": {\n",
    "        \"cpu_cores\": 4,\n",
    "        \"memory_gb\": 256,  # Assumed from esxi-33\n",
    "        \"gpu_count\": 1,   # NVIDIA GeForce RTX2080Ti * 1\n",
    "        \"gpu_memory_gb\": 11,\n",
    "        \"power_active\": 2200,  # Assumed from esxi-33\n",
    "        \"power_idle\": 1540,    # 70% of active\n",
    "        \"power_standby\": 220   # 10% of active\n",
    "    },\n",
    "    \"esxi-34\": {\n",
    "        \"cpu_cores\": 36,  # 18 * 2\n",
    "        \"memory_gb\": 256,\n",
    "        \"gpu_count\": 8,   # NVIDIA GeForce RTX2080Ti * 8\n",
    "        \"gpu_memory_gb\": 11 * 8,  # Approx. 11GB per RTX2080Ti\n",
    "        \"power_active\": 4400,  # 2200 * 2\n",
    "        \"power_idle\": 3080,    # 70% of active\n",
    "        \"power_standby\": 440   # 10% of active\n",
    "    },\n",
    "    \"node-161\": {\n",
    "        \"cpu_cores\": 4,\n",
    "        \"memory_gb\": 256,  # Assumed from esxi-34\n",
    "        \"gpu_count\": 1,   # NVIDIA GeForce RTX2080Ti * 1\n",
    "        \"gpu_memory_gb\": 11,\n",
    "        \"power_active\": 2200,  # Assumed from esxi-34\n",
    "        \"power_idle\": 1540,    # 70% of active\n",
    "        \"power_standby\": 220   # 10% of active\n",
    "    },\n",
    "    \"node-162\": {\n",
    "        \"cpu_cores\": 4,\n",
    "        \"memory_gb\": 256,  # Assumed from esxi-34\n",
    "        \"gpu_count\": 1,   # NVIDIA GeForce RTX2080Ti * 1\n",
    "        \"gpu_memory_gb\": 11,\n",
    "        \"power_active\": 2200,  # Assumed from esxi-34\n",
    "        \"power_idle\": 1540,    # 70% of active\n",
    "        \"power_standby\": 220   # 10% of active\n",
    "    },\n",
    "    \"node-163\": {\n",
    "        \"cpu_cores\": 4,\n",
    "        \"memory_gb\": 256,  # Assumed from esxi-34\n",
    "        \"gpu_count\": 0,   # No GPU\n",
    "        \"gpu_memory_gb\": 0,\n",
    "        \"power_active\": 2200,  # Assumed from esxi-34\n",
    "        \"power_idle\": 1540,    # 70% of active\n",
    "        \"power_standby\": 220   # 10% of active\n",
    "    },\n",
    "    \"node-164\": {\n",
    "        \"cpu_cores\": 4,\n",
    "        \"memory_gb\": 256,  # Assumed from esxi-34\n",
    "        \"gpu_count\": 1,   # NVIDIA GeForce RTX2080Ti * 1\n",
    "        \"gpu_memory_gb\": 11,\n",
    "        \"power_active\": 2200,  # Assumed from esxi-34\n",
    "        \"power_idle\": 1540,    # 70% of active\n",
    "        \"power_standby\": 220   # 10% of active\n",
    "    },\n",
    "    \"node-165\": {\n",
    "        \"cpu_cores\": 4,\n",
    "        \"memory_gb\": 256,  # Assumed from esxi-34\n",
    "        \"gpu_count\": 0,   # No GPU\n",
    "        \"gpu_memory_gb\": 0,\n",
    "        \"power_active\": 2200,  # Assumed from esxi-34\n",
    "        \"power_idle\": 1540,    # 70% of active\n",
    "        \"power_standby\": 220   # 10% of active\n",
    "    },\n",
    "    \"node-166\": {\n",
    "        \"cpu_cores\": 4,\n",
    "        \"memory_gb\": 256,  # Assumed from esxi-34\n",
    "        \"gpu_count\": 1,   # NVIDIA GeForce RTX2080Ti * 1\n",
    "        \"gpu_memory_gb\": 11,\n",
    "        \"power_active\": 2200,  # Assumed from esxi-34\n",
    "        \"power_idle\": 1540,    # 70% of active\n",
    "        \"power_standby\": 220   # 10% of active\n",
    "    },\n",
    "    \"node-167\": {\n",
    "        \"cpu_cores\": 4,\n",
    "        \"memory_gb\": 256,  # Assumed from esxi-34\n",
    "        \"gpu_count\": 0,   # No GPU\n",
    "        \"gpu_memory_gb\": 0,\n",
    "        \"power_active\": 2200,  # Assumed from esxi-34\n",
    "        \"power_idle\": 1540,    # 70% of active\n",
    "        \"power_standby\": 220   # 10% of active\n",
    "    },\n",
    "    \"node-168\": {\n",
    "        \"cpu_cores\": 4,\n",
    "        \"memory_gb\": 256,  # Assumed from esxi-34\n",
    "        \"gpu_count\": 1,   # NVIDIA GeForce RTX2080Ti * 1\n",
    "        \"gpu_memory_gb\": 11,\n",
    "        \"power_active\": 2200,  # Assumed from esxi-34\n",
    "        \"power_idle\": 1540,    # 70% of active\n",
    "        \"power_standby\": 220   # 10% of active\n",
    "    },\n",
    "    \"esxi-35\": {\n",
    "        \"cpu_cores\": 32,  # 16 * 2\n",
    "        \"memory_gb\": 128,\n",
    "        \"gpu_count\": 3,   # NVIDIA GeForce RTX2080Ti * 3\n",
    "        \"gpu_memory_gb\": 11 * 3,  # Approx. 11GB per RTX2080Ti\n",
    "        \"power_active\": 3200,  # 1600 * 2\n",
    "        \"power_idle\": 2240,    # 70% of active\n",
    "        \"power_standby\": 320   # 10% of active\n",
    "    },\n",
    "    \"node-141\": {\n",
    "        \"cpu_cores\": 4,\n",
    "        \"memory_gb\": 128,  # Assumed from esxi-35\n",
    "        \"gpu_count\": 1,   # NVIDIA GeForce RTX2080Ti * 1\n",
    "        \"gpu_memory_gb\": 11,\n",
    "        \"power_active\": 1600,  # Assumed from esxi-35\n",
    "        \"power_idle\": 1120,    # 70% of active\n",
    "        \"power_standby\": 160   # 10% of active\n",
    "    },\n",
    "    \"esxi-36\": {\n",
    "        \"cpu_cores\": 32,  # 16 * 2\n",
    "        \"memory_gb\": 128,\n",
    "        \"gpu_count\": 3,   # NVIDIA GeForce RTX3080 * 3\n",
    "        \"gpu_memory_gb\": 12 * 3,  # Approx. 12GB per RTX3080\n",
    "        \"power_active\": 2400,  # 2400 * 1\n",
    "        \"power_idle\": 1680,    # 70% of active\n",
    "        \"power_standby\": 240   # 10% of active\n",
    "    },\n",
    "    \"node-171\": {\n",
    "        \"cpu_cores\": 4,\n",
    "        \"memory_gb\": 128,  # Assumed from esxi-36\n",
    "        \"gpu_count\": 1,   # NVIDIA GeForce RTX3080 * 1\n",
    "        \"gpu_memory_gb\": 12,\n",
    "        \"power_active\": 2400,  # Assumed from esxi-36\n",
    "        \"power_idle\": 1680,    # 70% of active\n",
    "        \"power_standby\": 240   # 10% of active\n",
    "    },\n",
    "    \"node-172\": {\n",
    "        \"cpu_cores\": 4,\n",
    "        \"memory_gb\": 128,  # Assumed from esxi-36\n",
    "        \"gpu_count\": 2,   # NVIDIA GeForce RTX3080 * 2\n",
    "        \"gpu_memory_gb\": 12 * 2,\n",
    "        \"power_active\": 2400,  # Assumed from esxi-36\n",
    "        \"power_idle\": 1680,    # 70% of active\n",
    "        \"power_standby\": 240   # 10% of active\n",
    "    },\n",
    "    \"esxi-37\": {\n",
    "        \"cpu_cores\": 32,  # 16 * 2\n",
    "        \"memory_gb\": 128,\n",
    "        \"gpu_count\": 3,   # NVIDIA GeForce RTX3080 * 3\n",
    "        \"gpu_memory_gb\": 12 * 3,  # Approx. 12GB per RTX3080\n",
    "        \"power_active\": 2400,  # 2400 * 1\n",
    "        \"power_idle\": 1680,    # 70% of active\n",
    "        \"power_standby\": 240   # 10% of active\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "905e4fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jobsjobs [('AR', 0.802166666666666), ('IM', 1.2032499999999988), ('BE', 2.005416666666665)]\n",
      "jobsjobs [('AR', 0.203666666666666), ('IM', 0.305499999999999), ('BE', 0.509166666666665)]\n",
      "jobsjobs [('AR', 1.002166666666666), ('IM', 1.5032499999999989), ('BE', 2.505416666666665)]\n",
      "jobsjobs [('AR', 0.000333333333333334), ('IM', 0.000500000000000001), ('BE', 0.000833333333333335)]\n",
      "jobsjobs [('AR', 5.60083333333334), ('IM', 8.40125000000001), ('BE', 14.00208333333335)]\n",
      "jobsjobs [('AR', 0.20450000000000002), ('IM', 0.30674999999999997), ('BE', 0.51125)]\n",
      "jobsjobs [('AR', 7.2), ('IM', 10.799999999999999), ('BE', 18.0)]\n",
      "jobsjobs [('AR', 0.8006666666666661), ('IM', 1.200999999999999), ('BE', 2.001666666666665)]\n",
      "jobsjobs [('AR', 0.0001666666666666666), ('IM', 0.0002499999999999999), ('BE', 0.0004166666666666665)]\n",
      "jobsjobs [('AR', 0.8025000000000001), ('IM', 1.20375), ('BE', 2.00625)]\n",
      "jobsjobs [('AR', 0.8276666666666661), ('IM', 1.241499999999999), ('BE', 2.069166666666665)]\n",
      "jobsjobs [('AR', 0.8045), ('IM', 1.20675), ('BE', 2.01125)]\n",
      "jobsjobs [('AR', 0.005000000000000001), ('IM', 0.0075), ('BE', 0.0125)]\n",
      "jobsjobs [('AR', 0.20266666666666602), ('IM', 0.303999999999999), ('BE', 0.506666666666665)]\n",
      "jobsjobs [('AR', 19.02083333333334), ('IM', 28.53125000000001), ('BE', 47.55208333333335)]\n",
      "jobsjobs [('AR', 8.82533333333334), ('IM', 13.23800000000001), ('BE', 22.06333333333335)]\n",
      "jobsjobs [('AR', 5.3355), ('IM', 8.00325), ('BE', 13.33875)]\n",
      "jobsjobs [('AR', 8.8255), ('IM', 13.238249999999999), ('BE', 22.06375)]\n",
      "jobsjobs [('AR', 0.203666666666666), ('IM', 0.305499999999999), ('BE', 0.509166666666665)]\n",
      "jobsjobs [('AR', 8.83), ('IM', 13.245), ('BE', 22.075)]\n",
      "jobsjobs [('AR', 0.000833333333333334), ('IM', 0.001250000000000001), ('BE', 0.002083333333333335)]\n",
      "jobsjobs [('AR', 0.801166666666666), ('IM', 1.201749999999999), ('BE', 2.002916666666665)]\n",
      "jobsjobs [('AR', 5.50216666666666), ('IM', 8.253249999999989), ('BE', 13.75541666666665)]\n",
      "jobsjobs [('AR', 8.635), ('IM', 12.952499999999999), ('BE', 21.5875)]\n",
      "jobsjobs [('AR', 5.6035), ('IM', 8.405249999999999), ('BE', 14.00875)]\n",
      "jobsjobs [('AR', 0.0001666666666666666), ('IM', 0.0002499999999999999), ('BE', 0.0004166666666666665)]\n",
      "jobsjobs [('AR', 0.001333333333333334), ('IM', 0.002000000000000001), ('BE', 0.003333333333333335)]\n",
      "jobsjobs [('AR', 7.20033333333334), ('IM', 10.80050000000001), ('BE', 18.00083333333335)]\n",
      "jobsjobs [('AR', 0.2025), ('IM', 0.30374999999999996), ('BE', 0.50625)]\n",
      "jobsjobs [('AR', 0.20383333333333403), ('IM', 0.305750000000001), ('BE', 0.509583333333335)]\n",
      "jobsjobs [('AR', 0.800166666666666), ('IM', 1.200249999999999), ('BE', 2.000416666666665)]\n",
      "Scheduling Results:\n",
      "Total Energy Consumption (Watt-minutes): 4771200\n",
      "Job Success Rate (%): 100.00\n",
      "Number of Active Hosts: 21\n",
      "Node node-32 - State: Active, CPU Used: 13.75541666666665, GPU Power Used: 137.5541666666665, Power: 4400 Watts\n",
      "Node node-11 - State: Active, CPU Used: 22.06375, GPU Power Used: 0, Power: 2200 Watts\n",
      "Node node-12 - State: Active, CPU Used: 22.075, GPU Power Used: 0, Power: 2200 Watts\n",
      "Node node-13 - State: Active, CPU Used: 22.06333333333335, GPU Power Used: 0, Power: 2200 Watts\n",
      "Node node-14 - State: Active, CPU Used: 47.55208333333335, GPU Power Used: 0, Power: 2200 Watts\n",
      "Node esxi-31 - State: Idle, CPU Used: 0, GPU Power Used: 0, Power: 2240 Watts\n",
      "Node node-15 - State: Active, CPU Used: 0.0075, GPU Power Used: 0.075, Power: 1600 Watts\n",
      "Node node-16 - State: Active, CPU Used: 0.0004166666666666665, GPU Power Used: 0.004166666666666665, Power: 1600 Watts\n",
      "Node node-17 - State: Active, CPU Used: 18.00083333333335, GPU Power Used: 0, Power: 3200 Watts\n",
      "Node node-18 - State: Active, CPU Used: 14.00875, GPU Power Used: 0, Power: 3200 Watts\n",
      "Node node-19 - State: Active, CPU Used: 21.5875, GPU Power Used: 0, Power: 6400 Watts\n",
      "Node esxi-33 - State: Idle, CPU Used: 0, GPU Power Used: 0, Power: 3080 Watts\n",
      "Node node-151 - State: Idle, CPU Used: 0, GPU Power Used: 0, Power: 1540 Watts\n",
      "Node node-152 - State: Idle, CPU Used: 0, GPU Power Used: 0, Power: 1540 Watts\n",
      "Node node-153 - State: Idle, CPU Used: 0, GPU Power Used: 0, Power: 1540 Watts\n",
      "Node node-154 - State: Idle, CPU Used: 0, GPU Power Used: 0, Power: 1540 Watts\n",
      "Node node-155 - State: Idle, CPU Used: 0, GPU Power Used: 0, Power: 1540 Watts\n",
      "Node node-156 - State: Idle, CPU Used: 0, GPU Power Used: 0, Power: 1540 Watts\n",
      "Node node-157 - State: Idle, CPU Used: 0, GPU Power Used: 0, Power: 1540 Watts\n",
      "Node node-158 - State: Idle, CPU Used: 0, GPU Power Used: 0, Power: 1540 Watts\n",
      "Node esxi-34 - State: Idle, CPU Used: 0, GPU Power Used: 0, Power: 3080 Watts\n",
      "Node node-161 - State: Active, CPU Used: 2.002916666666665, GPU Power Used: 20.029166666666647, Power: 2200 Watts\n",
      "Node node-162 - State: Active, CPU Used: 0.8276666666666661, GPU Power Used: 8.27666666666666, Power: 2200 Watts\n",
      "Node node-163 - State: Active, CPU Used: 2.00625, GPU Power Used: 0, Power: 2200 Watts\n",
      "Node node-164 - State: Active, CPU Used: 0.509166666666665, GPU Power Used: 5.09166666666665, Power: 2200 Watts\n",
      "Node node-165 - State: Active, CPU Used: 2.000416666666665, GPU Power Used: 0, Power: 2200 Watts\n",
      "Node node-166 - State: Active, CPU Used: 0.509583333333335, GPU Power Used: 5.095833333333351, Power: 2200 Watts\n",
      "Node node-167 - State: Active, CPU Used: 2.005416666666665, GPU Power Used: 0, Power: 2200 Watts\n",
      "Node node-168 - State: Active, CPU Used: 0.50625, GPU Power Used: 5.0625, Power: 2200 Watts\n",
      "Node esxi-35 - State: Idle, CPU Used: 0, GPU Power Used: 0, Power: 2240 Watts\n",
      "Node node-141 - State: Active, CPU Used: 0.506666666666665, GPU Power Used: 5.06666666666665, Power: 1600 Watts\n",
      "Node esxi-36 - State: Idle, CPU Used: 0, GPU Power Used: 0, Power: 1680 Watts\n",
      "Node node-171 - State: Active, CPU Used: 0.003333333333333335, GPU Power Used: 0.03333333333333335, Power: 2400 Watts\n",
      "Node node-172 - State: Active, CPU Used: 0.0004166666666666665, GPU Power Used: 0.004166666666666665, Power: 2400 Watts\n",
      "Node esxi-37 - State: Idle, CPU Used: 0, GPU Power Used: 0, Power: 1680 Watts\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "# Node Specifications (Updated with all nodes)\n",
    "\n",
    "\n",
    "# Constants from the paper\n",
    "JOB_TYPES = [\"AR\", \"IM\", \"BE\"]  # Advance Reservation, Immediate, Best Effort\n",
    "JOB_DISTRIBUTION = {\"AR\": 0.2, \"IM\": 0.3, \"BE\": 0.5}  # Percentage of each job type\n",
    "IDLE_THRESHOLD_MINUTES = 30  # I_th\n",
    "MIN_IDLE_HOSTS = 1\n",
    "\n",
    "# Load new workload data (15:00 to 16:00 on 2024-11-04)\n",
    "workload_data = [\n",
    "    {\"hour\": \"2024-11-04 15:00:00\", \"nodename\": \"node-167\", \"cpu_load\": 4.01083333333333, \"cpu_alloc\": 4.0, \"cpu_idle\": 0.0, \"cpu_total\": 4.0, \"gpu_power_usage\": 0.0, \"gpu_mem_used\": 0.0, \"gpu_gpu_usage\": 0.0, \"gpu_fan\": 0.0},\n",
    "    {\"hour\": \"2024-11-04 15:00:00\", \"nodename\": \"node-168\", \"cpu_load\": 1.01833333333333, \"cpu_alloc\": 2.0, \"cpu_idle\": 2.0, \"cpu_total\": 4.0, \"gpu_power_usage\": 62.7775, \"gpu_mem_used\": 296.666666666667, \"gpu_gpu_usage\": 2.91666666666667, \"gpu_fan\": 0.0},\n",
    "    {\"hour\": \"2024-11-04 15:00:00\", \"nodename\": \"node-19\", \"cpu_load\": 5.01083333333333, \"cpu_alloc\": 5.0, \"cpu_idle\": 75.0, \"cpu_total\": 80.0, \"gpu_power_usage\": 0.0, \"gpu_mem_used\": 0.0, \"gpu_gpu_usage\": 0.0, \"gpu_fan\": 0.0},\n",
    "    {\"hour\": \"2024-11-04 15:00:00\", \"nodename\": \"node-171\", \"cpu_load\": 0.00166666666666667, \"cpu_alloc\": 0.0, \"cpu_idle\": 4.0, \"cpu_total\": 4.0, \"gpu_power_usage\": 59.8541666666667, \"gpu_mem_used\": 1.0, \"gpu_gpu_usage\": 0.0, \"gpu_fan\": 30.0},\n",
    "    {\"hour\": \"2024-11-04 15:00:00\", \"nodename\": \"node-18\", \"cpu_load\": 28.0041666666667, \"cpu_alloc\": 36.0, \"cpu_idle\": 0.0, \"cpu_total\": 36.0, \"gpu_power_usage\": 0.0, \"gpu_mem_used\": 0.0, \"gpu_gpu_usage\": 0.0, \"gpu_fan\": 0.0},\n",
    "    {\"hour\": \"2024-11-04 15:00:00\", \"nodename\": \"node-166\", \"cpu_load\": 1.0225, \"cpu_alloc\": 2.0, \"cpu_idle\": 2.0, \"cpu_total\": 4.0, \"gpu_power_usage\": 75.3408333333333, \"gpu_mem_used\": 298.166666666667, \"gpu_gpu_usage\": 1.75, \"gpu_fan\": 0.0},\n",
    "    {\"hour\": \"2024-11-04 15:00:00\", \"nodename\": \"node-17\", \"cpu_load\": 36.0, \"cpu_alloc\": 36.0, \"cpu_idle\": 0.0, \"cpu_total\": 36.0, \"gpu_power_usage\": 0.0, \"gpu_mem_used\": 0.0, \"gpu_gpu_usage\": 0.0, \"gpu_fan\": 0.0},\n",
    "    {\"hour\": \"2024-11-04 15:00:00\", \"nodename\": \"node-165\", \"cpu_load\": 4.00333333333333, \"cpu_alloc\": 4.0, \"cpu_idle\": 0.0, \"cpu_total\": 4.0, \"gpu_power_usage\": 0.0, \"gpu_mem_used\": 0.0, \"gpu_gpu_usage\": 0.0, \"gpu_fan\": 0.0},\n",
    "    {\"hour\": \"2024-11-04 15:00:00\", \"nodename\": \"node-16\", \"cpu_load\": 0.000833333333333333, \"cpu_alloc\": 0.0, \"cpu_idle\": 4.0, \"cpu_total\": 4.0, \"gpu_power_usage\": 34.5375, \"gpu_mem_used\": 1.0, \"gpu_gpu_usage\": 0.0, \"gpu_fan\": 0.0},\n",
    "    {\"hour\": \"2024-11-04 15:00:00\", \"nodename\": \"node-163\", \"cpu_load\": 4.0125, \"cpu_alloc\": 4.0, \"cpu_idle\": 0.0, \"cpu_total\": 4.0, \"gpu_power_usage\": 0.0, \"gpu_mem_used\": 0.0, \"gpu_gpu_usage\": 0.0, \"gpu_fan\": 0.0},\n",
    "    {\"hour\": \"2024-11-04 15:00:00\", \"nodename\": \"node-162\", \"cpu_load\": 4.13833333333333, \"cpu_alloc\": 4.0, \"cpu_idle\": 0.0, \"cpu_total\": 4.0, \"gpu_power_usage\": 93.5875, \"gpu_mem_used\": 7397.0, \"gpu_gpu_usage\": 33.8333333333333, \"gpu_fan\": 0.0},\n",
    "    {\"hour\": \"2024-11-04 15:00:00\", \"nodename\": \"node-161\", \"cpu_load\": 4.0225, \"cpu_alloc\": 4.0, \"cpu_idle\": 0.0, \"cpu_total\": 4.0, \"gpu_power_usage\": 75.4791666666667, \"gpu_mem_used\": 279.0, \"gpu_gpu_usage\": 24.0833333333333, \"gpu_fan\": 0.0},\n",
    "    {\"hour\": \"2024-11-04 15:00:00\", \"nodename\": \"node-15\", \"cpu_load\": 0.025, \"cpu_alloc\": 1.0, \"cpu_idle\": 3.0, \"cpu_total\": 4.0, \"gpu_power_usage\": 36.1758333333333, \"gpu_mem_used\": 6863.0, \"gpu_gpu_usage\": 0.0, \"gpu_fan\": 0.0},\n",
    "    {\"hour\": \"2024-11-04 15:00:00\", \"nodename\": \"node-141\", \"cpu_load\": 1.01333333333333, \"cpu_alloc\": 2.0, \"cpu_idle\": 2.0, \"cpu_total\": 4.0, \"gpu_power_usage\": 72.4166666666667, \"gpu_mem_used\": 296.333333333333, \"gpu_gpu_usage\": 1.16666666666667, \"gpu_fan\": 29.0},\n",
    "    {\"hour\": \"2024-11-04 15:00:00\", \"nodename\": \"node-14\", \"cpu_load\": 95.1041666666667, \"cpu_alloc\": 95.0, \"cpu_idle\": 1.0, \"cpu_total\": 96.0, \"gpu_power_usage\": 0.0, \"gpu_mem_used\": 0.0, \"gpu_gpu_usage\": 0.0, \"gpu_fan\": 0.0},\n",
    "    {\"hour\": \"2024-11-04 15:00:00\", \"nodename\": \"node-13\", \"cpu_load\": 44.1266666666667, \"cpu_alloc\": 44.0, \"cpu_idle\": 0.0, \"cpu_total\": 44.0, \"gpu_power_usage\": 0.0, \"gpu_mem_used\": 0.0, \"gpu_gpu_usage\": 0.0, \"gpu_fan\": 0.0},\n",
    "    {\"hour\": \"2024-11-04 15:00:00\", \"nodename\": \"node-32\", \"cpu_load\": 26.6775, \"cpu_alloc\": 30.0, \"cpu_idle\": 2.0, \"cpu_total\": 32.0, \"gpu_power_usage\": 102.4059375, \"gpu_mem_used\": 8790.20833333333, \"gpu_gpu_usage\": 26.4166666666667, \"gpu_fan\": 0.0},\n",
    "    {\"hour\": \"2024-11-04 15:00:00\", \"nodename\": \"node-11\", \"cpu_load\": 44.1275, \"cpu_alloc\": 44.0, \"cpu_idle\": 0.0, \"cpu_total\": 44.0, \"gpu_power_usage\": 0.0, \"gpu_mem_used\": 0.0, \"gpu_gpu_usage\": 0.0, \"gpu_fan\": 0.0},\n",
    "    {\"hour\": \"2024-11-04 15:00:00\", \"nodename\": \"node-164\", \"cpu_load\": 1.01833333333333, \"cpu_alloc\": 2.0, \"cpu_idle\": 2.0, \"cpu_total\": 4.0, \"gpu_power_usage\": 59.665, \"gpu_mem_used\": 295.833333333333, \"gpu_gpu_usage\": 1.58333333333333, \"gpu_fan\": 0.0},\n",
    "    {\"hour\": \"2024-11-04 15:00:00\", \"nodename\": \"node-12\", \"cpu_load\": 44.15, \"cpu_alloc\": 44.0, \"cpu_idle\": 0.0, \"cpu_total\": 44.0, \"gpu_power_usage\": 0.0, \"gpu_mem_used\": 0.0, \"gpu_gpu_usage\": 0.0, \"gpu_fan\": 0.0},\n",
    "    {\"hour\": \"2024-11-04 15:00:00\", \"nodename\": \"node-172\", \"cpu_load\": 0.00416666666666667, \"cpu_alloc\": 0.0, \"cpu_idle\": 4.0, \"cpu_total\": 4.0, \"gpu_power_usage\": 54.8358333333333, \"gpu_mem_used\": 1.0, \"gpu_gpu_usage\": 0.0, \"gpu_fan\": 30.0},\n",
    "    {\"hour\": \"2024-11-04 16:00:00\", \"nodename\": \"node-161\", \"cpu_load\": 4.00583333333333, \"cpu_alloc\": 4.0, \"cpu_idle\": 0.0, \"cpu_total\": 4.0, \"gpu_power_usage\": 74.98, \"gpu_mem_used\": 279.0, \"gpu_gpu_usage\": 24.9166666666667, \"gpu_fan\": 0.0},\n",
    "    {\"hour\": \"2024-11-04 16:00:00\", \"nodename\": \"node-32\", \"cpu_load\": 27.5108333333333, \"cpu_alloc\": 30.0, \"cpu_idle\": 2.0, \"cpu_total\": 32.0, \"gpu_power_usage\": 91.5228125, \"gpu_mem_used\": 8959.25, \"gpu_gpu_usage\": 20.7395833333333, \"gpu_fan\": 0.0},\n",
    "    {\"hour\": \"2024-11-04 16:00:00\", \"nodename\": \"node-19\", \"cpu_load\": 43.175, \"cpu_alloc\": 43.5, \"cpu_idle\": 36.5, \"cpu_total\": 80.0, \"gpu_power_usage\": 0.0, \"gpu_mem_used\": 0.0, \"gpu_gpu_usage\": 0.0, \"gpu_fan\": 0.0},\n",
    "    {\"hour\": \"2024-11-04 16:00:00\", \"nodename\": \"node-18\", \"cpu_load\": 28.0175, \"cpu_alloc\": 36.0, \"cpu_idle\": 0.0, \"cpu_total\": 36.0, \"gpu_power_usage\": 0.0, \"gpu_mem_used\": 0.0, \"gpu_gpu_usage\": 0.0, \"gpu_fan\": 0.0},\n",
    "    {\"hour\": \"2024-11-04 16:00:00\", \"nodename\": \"node-172\", \"cpu_load\": 0.000833333333333333, \"cpu_alloc\": 0.0, \"cpu_idle\": 4.0, \"cpu_total\": 4.0, \"gpu_power_usage\": 54.9441666666667, \"gpu_mem_used\": 1.0, \"gpu_gpu_usage\": 0.0, \"gpu_fan\": 30.0},\n",
    "    {\"hour\": \"2024-11-04 16:00:00\", \"nodename\": \"node-171\", \"cpu_load\": 0.00666666666666667, \"cpu_alloc\": 0.0, \"cpu_idle\": 4.0, \"cpu_total\": 4.0, \"gpu_power_usage\": 60.1966666666667, \"gpu_mem_used\": 1.0, \"gpu_gpu_usage\": 0.0, \"gpu_fan\": 30.0},\n",
    "    {\"hour\": \"2024-11-04 16:00:00\", \"nodename\": \"node-17\", \"cpu_load\": 36.0016666666667, \"cpu_alloc\": 36.0, \"cpu_idle\": 0.0, \"cpu_total\": 36.0, \"gpu_power_usage\": 0.0, \"gpu_mem_used\": 0.0, \"gpu_gpu_usage\": 0.0, \"gpu_fan\": 0.0},\n",
    "    {\"hour\": \"2024-11-04 16:00:00\", \"nodename\": \"node-168\", \"cpu_load\": 1.0125, \"cpu_alloc\": 2.0, \"cpu_idle\": 2.0, \"cpu_total\": 4.0, \"gpu_power_usage\": 58.6608333333333, \"gpu_mem_used\": 297.666666666667, \"gpu_gpu_usage\": 0.916666666666667, \"gpu_fan\": 0.0},\n",
    "    {\"hour\": \"2024-11-04 16:00:00\", \"nodename\": \"node-166\", \"cpu_load\": 1.01916666666667, \"cpu_alloc\": 2.0, \"cpu_idle\": 2.0, \"cpu_total\": 4.0, \"gpu_power_usage\": 66.7841666666667, \"gpu_mem_used\": 295.0, \"gpu_gpu_usage\": 1.58333333333333, \"gpu_fan\": 0.0},\n",
    "    {\"hour\": \"2024-11-04 16:00:00\", \"nodename\": \"node-165\", \"cpu_load\": 4.00083333333333, \"cpu_alloc\": 4.0, \"cpu_idle\": 0.0, \"cpu_total\": 4.0, \"gpu_power_usage\": 0.0, \"gpu_mem_used\": 0.0, \"gpu_gpu_usage\": 0.0, \"gpu_fan\": 0.0}\n",
    "]\n",
    "\n",
    "workload = pd.DataFrame(workload_data)\n",
    "\n",
    "# Function to classify jobs based on resource usage\n",
    "def classify_jobs(cpu_load: float, job_dist: Dict) -> List[Tuple[str, float]]:\n",
    "    \n",
    "    total_load = cpu_load    # type(cpu_load) = pandas.core.series.Series\n",
    "    jobs = []\n",
    "    for job_type, perc in job_dist.items(): # JOB_DISTRIBUTION = {\"AR\": 0.2, \"IM\": 0.3, \"BE\": 0.5}  # Percentage of each job type\n",
    "        load = total_load * perc # 用電量沒那麼高\n",
    "        jobs.append((job_type, load))\n",
    "        \n",
    "    print(\"jobsjobs\", jobs)\n",
    "    return jobs\n",
    "\n",
    "# Node class to manage state and resources\n",
    "class Node:\n",
    "    def __init__(self, name: str):\n",
    "        self.name = name\n",
    "        self.state = \"Idle\"  # Start in Idle state\n",
    "        self.cpu_used = 0\n",
    "        self.gpu_power_used = 0\n",
    "        self.gpu_mem_used = 0\n",
    "        self.vm_queue = []  # List of jobs (VM requests) in queue\n",
    "        self.last_active_time = None\n",
    "        self.available_time = 0  # Earliest available time for VMs\n",
    "\n",
    "    def update_state(self, time_minutes: float, job_load: float = 0):\n",
    "        if job_load > 0 and self.state in [\"Idle\", \"Standby\"]:\n",
    "            self.state = \"Active\"\n",
    "            self.last_active_time = time_minutes\n",
    "        elif job_load == 0 and self.state == \"Active\":\n",
    "            if time_minutes - self.last_active_time > IDLE_THRESHOLD_MINUTES:\n",
    "                self.state = \"Standby\"\n",
    "            else:\n",
    "                self.state = \"Idle\"\n",
    "        self.cpu_used = job_load\n",
    "        # Update GPU usage if applicable (simplified for now)\n",
    "        if NODE_SPEC[self.name][\"gpu_count\"] > 0:\n",
    "            self.gpu_power_used = job_load * 10  # Placeholder: adjust based on actual GPU load\n",
    "\n",
    "    def get_power_consumption(self) -> float:\n",
    "        if self.state == \"Active\":\n",
    "            return NODE_SPEC[self.name][\"power_active\"]\n",
    "        elif self.state == \"Idle\":\n",
    "            return NODE_SPEC[self.name][\"power_idle\"]\n",
    "        else:  # Standby\n",
    "            return NODE_SPEC[self.name][\"power_standby\"]\n",
    "\n",
    "    def can_handle_job(self, cpu_load: float, gpu_power: float, gpu_mem: float) -> bool:\n",
    "        cpu_capacity = NODE_SPEC[self.name][\"cpu_cores\"] * 100  # Assume 100 units/core\n",
    "        gpu_capacity = NODE_SPEC[self.name][\"gpu_count\"] * 100  # Placeholder GPU capacity\n",
    "        return (self.cpu_used + cpu_load <= cpu_capacity and \n",
    "                (NODE_SPEC[self.name][\"gpu_count\"] == 0 or \n",
    "                 (self.gpu_power_used + gpu_power <= gpu_capacity and \n",
    "                  self.gpu_mem_used + gpu_mem <= NODE_SPEC[self.name][\"gpu_memory_gb\"] * 1024)))  # Convert GB to MB\n",
    "\n",
    "# EAVMAT Scheduling Algorithm\n",
    "def eavmat_scheduling(nodes: List[Node], workload: pd.DataFrame) -> Dict:\n",
    "    results = {\"energy_consumption\": 0, \"job_success_rate\": 0, \"active_hosts\": 0}\n",
    "    total_jobs = 0\n",
    "    successful_jobs = 0\n",
    "\n",
    "    for idx, row in workload.iterrows():\n",
    "        time = pd.to_datetime(row[\"hour\"])\n",
    "        cpu_load = row[\"cpu_load\"]\n",
    "        gpu_power = row[\"gpu_power_usage\"]\n",
    "        gpu_mem = row[\"gpu_mem_used\"]\n",
    "        nodename = row[\"nodename\"]\n",
    "\n",
    "        # Classify jobs into AR, IM, BE for this node\n",
    "        jobs = classify_jobs(cpu_load, JOB_DISTRIBUTION)\n",
    "        total_jobs += len(jobs)\n",
    "\n",
    "        # Get the specific node\n",
    "        node = next(n for n in nodes if n.name == nodename)\n",
    "\n",
    "        for job_type, load in jobs:\n",
    "            scheduled = False\n",
    "            # Try to schedule on the specific node first (since workload is per node)\n",
    "            if node.can_handle_job(load, gpu_power, gpu_mem):\n",
    "                node.cpu_used += load\n",
    "                if NODE_SPEC[nodename][\"gpu_count\"] > 0:\n",
    "                    node.gpu_power_used += gpu_power\n",
    "                    node.gpu_mem_used += gpu_mem\n",
    "                node.update_state((time - pd.Timestamp(\"2024-11-04 15:00:00\")).total_seconds() / 60, load)\n",
    "                node.available_time = (time + timedelta(hours=1) - pd.Timestamp(\"2024-11-04 15:00:00\")).total_seconds() / 60\n",
    "                scheduled = True\n",
    "                successful_jobs += 1\n",
    "            else:\n",
    "                # If this node can't handle, try other active/idle nodes (simplified)\n",
    "                other_nodes = [n for n in nodes if n.name != nodename and n.state in [\"Active\", \"Idle\"]]\n",
    "                for other_node in sorted(other_nodes, key=lambda x: x.available_time):\n",
    "                    if other_node.can_handle_job(load, gpu_power, gpu_mem):\n",
    "                        other_node.cpu_used += load\n",
    "                        if NODE_SPEC[other_node.name][\"gpu_count\"] > 0:\n",
    "                            other_node.gpu_power_used += gpu_power\n",
    "                            other_node.gpu_mem_used += gpu_mem\n",
    "                        other_node.update_state((time - pd.Timestamp(\"2024-11-04 15:00:00\")).total_seconds() / 60, load)\n",
    "                        other_node.available_time = (time + timedelta(hours=1) - pd.Timestamp(\"2024-11-04 15:00:00\")).total_seconds() / 60\n",
    "                        other_node.state = \"Active\"\n",
    "                        scheduled = True\n",
    "                        successful_jobs += 1\n",
    "                        break\n",
    "\n",
    "            if not scheduled and job_type in [\"AR\", \"IM\"]:\n",
    "                # Preempt BE job if possible (simplified: assume BE jobs can be preempted on this node or others)\n",
    "                for target_node in [node] + other_nodes:\n",
    "                    if target_node.vm_queue and any(j[0] == \"BE\" for j in target_node.vm_queue):\n",
    "                        target_node.vm_queue = [j for j in target_node.vm_queue if j[0] != \"BE\"]\n",
    "                        target_node.cpu_used += load\n",
    "                        if NODE_SPEC[target_node.name][\"gpu_count\"] > 0:\n",
    "                            target_node.gpu_power_used += gpu_power\n",
    "                            target_node.gpu_mem_used += gpu_mem\n",
    "                        target_node.update_state((time - pd.Timestamp(\"2024-11-04 15:00:00\")).total_seconds() / 60, load)\n",
    "                        target_node.available_time = (time + timedelta(hours=1) - pd.Timestamp(\"2024-11-04 15:00:00\")).total_seconds() / 60\n",
    "                        scheduled = True\n",
    "                        successful_jobs += 1\n",
    "                        break\n",
    "\n",
    "            if not scheduled:\n",
    "                # Job rejected (e.g., for AR/IM if no resources available)\n",
    "                continue\n",
    "\n",
    "    # Calculate energy consumption over 1 hour (60 minutes)\n",
    "    total_time_minutes = 60\n",
    "    for node in nodes:\n",
    "        state_time = total_time_minutes  # Simplified: assume node stays in current state for entire period\n",
    "        results[\"energy_consumption\"] += node.get_power_consumption() * state_time\n",
    "\n",
    "    results[\"job_success_rate\"] = (successful_jobs / total_jobs) * 100 if total_jobs > 0 else 0\n",
    "    results[\"active_hosts\"] = len([n for n in nodes if n.state == \"Active\"])\n",
    "\n",
    "    return results\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize all nodes\n",
    "    nodes = [Node(name) for name in NODE_SPEC.keys()]\n",
    "\n",
    "    # Run EAVMAT scheduling\n",
    "    results = eavmat_scheduling(nodes, workload)\n",
    "\n",
    "    # Print results\n",
    "    print(\"Scheduling Results:\")\n",
    "    print(f\"Total Energy Consumption (Watt-minutes): {results['energy_consumption']}\")\n",
    "    print(f\"Job Success Rate (%): {results['job_success_rate']:.2f}\")\n",
    "    print(f\"Number of Active Hosts: {results['active_hosts']}\")\n",
    "\n",
    "    # Optional: Print node states\n",
    "    for node in nodes:\n",
    "        print(f\"Node {node.name} - State: {node.state}, CPU Used: {node.cpu_used}, GPU Power Used: {node.gpu_power_used}, Power: {node.get_power_consumption()} Watts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7720950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jobsjobs [('AR', 0.802166666666666), ('IM', 1.2032499999999988), ('BE', 2.005416666666665)]\n",
      "jobsjobs [('AR', 0.203666666666666), ('IM', 0.305499999999999), ('BE', 0.509166666666665)]\n",
      "jobsjobs [('AR', 1.002166666666666), ('IM', 1.5032499999999989), ('BE', 2.505416666666665)]\n",
      "jobsjobs [('AR', 0.000333333333333334), ('IM', 0.000500000000000001), ('BE', 0.000833333333333335)]\n",
      "jobsjobs [('AR', 5.60083333333334), ('IM', 8.40125000000001), ('BE', 14.00208333333335)]\n",
      "jobsjobs [('AR', 0.20450000000000002), ('IM', 0.30674999999999997), ('BE', 0.51125)]\n",
      "jobsjobs [('AR', 7.2), ('IM', 10.799999999999999), ('BE', 18.0)]\n",
      "jobsjobs [('AR', 0.8006666666666661), ('IM', 1.200999999999999), ('BE', 2.001666666666665)]\n",
      "jobsjobs [('AR', 0.0001666666666666666), ('IM', 0.0002499999999999999), ('BE', 0.0004166666666666665)]\n",
      "jobsjobs [('AR', 0.8025000000000001), ('IM', 1.20375), ('BE', 2.00625)]\n",
      "jobsjobs [('AR', 0.8276666666666661), ('IM', 1.241499999999999), ('BE', 2.069166666666665)]\n",
      "jobsjobs [('AR', 0.8045), ('IM', 1.20675), ('BE', 2.01125)]\n",
      "jobsjobs [('AR', 0.005000000000000001), ('IM', 0.0075), ('BE', 0.0125)]\n",
      "jobsjobs [('AR', 0.20266666666666602), ('IM', 0.303999999999999), ('BE', 0.506666666666665)]\n",
      "jobsjobs [('AR', 19.02083333333334), ('IM', 28.53125000000001), ('BE', 47.55208333333335)]\n",
      "jobsjobs [('AR', 8.82533333333334), ('IM', 13.23800000000001), ('BE', 22.06333333333335)]\n",
      "jobsjobs [('AR', 5.3355), ('IM', 8.00325), ('BE', 13.33875)]\n",
      "jobsjobs [('AR', 8.8255), ('IM', 13.238249999999999), ('BE', 22.06375)]\n",
      "jobsjobs [('AR', 0.203666666666666), ('IM', 0.305499999999999), ('BE', 0.509166666666665)]\n",
      "jobsjobs [('AR', 8.83), ('IM', 13.245), ('BE', 22.075)]\n",
      "jobsjobs [('AR', 0.000833333333333334), ('IM', 0.001250000000000001), ('BE', 0.002083333333333335)]\n",
      "jobsjobs [('AR', 0.801166666666666), ('IM', 1.201749999999999), ('BE', 2.002916666666665)]\n",
      "jobsjobs [('AR', 5.50216666666666), ('IM', 8.253249999999989), ('BE', 13.75541666666665)]\n",
      "jobsjobs [('AR', 8.635), ('IM', 12.952499999999999), ('BE', 21.5875)]\n",
      "jobsjobs [('AR', 5.6035), ('IM', 8.405249999999999), ('BE', 14.00875)]\n",
      "jobsjobs [('AR', 0.0001666666666666666), ('IM', 0.0002499999999999999), ('BE', 0.0004166666666666665)]\n",
      "jobsjobs [('AR', 0.001333333333333334), ('IM', 0.002000000000000001), ('BE', 0.003333333333333335)]\n",
      "jobsjobs [('AR', 7.20033333333334), ('IM', 10.80050000000001), ('BE', 18.00083333333335)]\n",
      "jobsjobs [('AR', 0.2025), ('IM', 0.30374999999999996), ('BE', 0.50625)]\n",
      "jobsjobs [('AR', 0.20383333333333403), ('IM', 0.305750000000001), ('BE', 0.509583333333335)]\n",
      "jobsjobs [('AR', 0.800166666666666), ('IM', 1.200249999999999), ('BE', 2.000416666666665)]\n",
      "Scheduling Results:\n",
      "Total Energy Consumption (Watt-minutes): 4771200\n",
      "Job Success Rate (%): 100.00\n",
      "Number of Active Hosts: 21\n",
      "Node node-32 - State: Active, CPU Used: 13.75541666666665, GPU Power Used: 137.5541666666665, Power: 4400 Watts\n",
      "Node node-11 - State: Active, CPU Used: 22.06375, GPU Power Used: 0, Power: 2200 Watts\n",
      "Node node-12 - State: Active, CPU Used: 22.075, GPU Power Used: 0, Power: 2200 Watts\n",
      "Node node-13 - State: Active, CPU Used: 22.06333333333335, GPU Power Used: 0, Power: 2200 Watts\n",
      "Node node-14 - State: Active, CPU Used: 47.55208333333335, GPU Power Used: 0, Power: 2200 Watts\n",
      "Node esxi-31 - State: Idle, CPU Used: 0, GPU Power Used: 0, Power: 2240 Watts\n",
      "Node node-15 - State: Active, CPU Used: 0.0075, GPU Power Used: 0.075, Power: 1600 Watts\n",
      "Node node-16 - State: Active, CPU Used: 0.0004166666666666665, GPU Power Used: 0.004166666666666665, Power: 1600 Watts\n",
      "Node node-17 - State: Active, CPU Used: 18.00083333333335, GPU Power Used: 0, Power: 3200 Watts\n",
      "Node node-18 - State: Active, CPU Used: 14.00875, GPU Power Used: 0, Power: 3200 Watts\n",
      "Node node-19 - State: Active, CPU Used: 21.5875, GPU Power Used: 0, Power: 6400 Watts\n",
      "Node esxi-33 - State: Idle, CPU Used: 0, GPU Power Used: 0, Power: 3080 Watts\n",
      "Node node-151 - State: Idle, CPU Used: 0, GPU Power Used: 0, Power: 1540 Watts\n",
      "Node node-152 - State: Idle, CPU Used: 0, GPU Power Used: 0, Power: 1540 Watts\n",
      "Node node-153 - State: Idle, CPU Used: 0, GPU Power Used: 0, Power: 1540 Watts\n",
      "Node node-154 - State: Idle, CPU Used: 0, GPU Power Used: 0, Power: 1540 Watts\n",
      "Node node-155 - State: Idle, CPU Used: 0, GPU Power Used: 0, Power: 1540 Watts\n",
      "Node node-156 - State: Idle, CPU Used: 0, GPU Power Used: 0, Power: 1540 Watts\n",
      "Node node-157 - State: Idle, CPU Used: 0, GPU Power Used: 0, Power: 1540 Watts\n",
      "Node node-158 - State: Idle, CPU Used: 0, GPU Power Used: 0, Power: 1540 Watts\n",
      "Node esxi-34 - State: Idle, CPU Used: 0, GPU Power Used: 0, Power: 3080 Watts\n",
      "Node node-161 - State: Active, CPU Used: 2.002916666666665, GPU Power Used: 20.029166666666647, Power: 2200 Watts\n",
      "Node node-162 - State: Active, CPU Used: 0.8276666666666661, GPU Power Used: 8.27666666666666, Power: 2200 Watts\n",
      "Node node-163 - State: Active, CPU Used: 2.00625, GPU Power Used: 0, Power: 2200 Watts\n",
      "Node node-164 - State: Active, CPU Used: 0.509166666666665, GPU Power Used: 5.09166666666665, Power: 2200 Watts\n",
      "Node node-165 - State: Active, CPU Used: 2.000416666666665, GPU Power Used: 0, Power: 2200 Watts\n",
      "Node node-166 - State: Active, CPU Used: 0.509583333333335, GPU Power Used: 5.095833333333351, Power: 2200 Watts\n",
      "Node node-167 - State: Active, CPU Used: 2.005416666666665, GPU Power Used: 0, Power: 2200 Watts\n",
      "Node node-168 - State: Active, CPU Used: 0.50625, GPU Power Used: 5.0625, Power: 2200 Watts\n",
      "Node esxi-35 - State: Idle, CPU Used: 0, GPU Power Used: 0, Power: 2240 Watts\n",
      "Node node-141 - State: Active, CPU Used: 0.506666666666665, GPU Power Used: 5.06666666666665, Power: 1600 Watts\n",
      "Node esxi-36 - State: Idle, CPU Used: 0, GPU Power Used: 0, Power: 1680 Watts\n",
      "Node node-171 - State: Active, CPU Used: 0.003333333333333335, GPU Power Used: 0.03333333333333335, Power: 2400 Watts\n",
      "Node node-172 - State: Active, CPU Used: 0.0004166666666666665, GPU Power Used: 0.004166666666666665, Power: 2400 Watts\n",
      "Node esxi-37 - State: Idle, CPU Used: 0, GPU Power Used: 0, Power: 1680 Watts\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize all nodes\n",
    "    nodes = [Node(name) for name in NODE_SPEC.keys()]\n",
    "\n",
    "    # Run EAVMAT scheduling\n",
    "    results = eavmat_scheduling(nodes, workload)\n",
    "\n",
    "    # Print results\n",
    "    print(\"Scheduling Results:\")\n",
    "    print(f\"Total Energy Consumption (Watt-minutes): {results['energy_consumption']}\")\n",
    "    print(f\"Job Success Rate (%): {results['job_success_rate']:.2f}\")\n",
    "    print(f\"Number of Active Hosts: {results['active_hosts']}\")\n",
    "\n",
    "    # Optional: Print node states\n",
    "    for node in nodes:\n",
    "        print(f\"Node {node.name} - State: {node.state}, CPU Used: {node.cpu_used}, GPU Power Used: {node.gpu_power_used}, Power: {node.get_power_consumption()} Watts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7796846",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
